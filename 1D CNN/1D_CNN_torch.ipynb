{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('iris.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107, 4, 1), (107,), (20, 4, 1), (20,), (23, 4, 1), (23,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Type the code for part 1 here ##\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[df.columns[:-1]].to_numpy()\n",
    "y_text = df[df.columns[-1]].to_numpy()\n",
    "y = np.array([0 if item=='setosa' else 1 if item=='versicolor' else 2 for item in y_text])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=2023)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=2023)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 4, 1).astype('float32')\n",
    "X_val = X_val.reshape(X_val.shape[0], 4, 1).astype('float32') \n",
    "X_test = X_test.reshape(X_test.shape[0], 4, 1).astype('float32') \n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PrepData(Dataset):\n",
    "    def __init__(self, data, label, device):\n",
    "        self.data = data\n",
    "        self.labels = torch.LongTensor(label)\n",
    "        self.device = device\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.from_numpy(np.array(y))\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "class DLtoDevice():\n",
    "    def __init__(self, data, device):\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.data: \n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisClassifier(\n",
      "  (conv_1d): Conv1d(4, 4, kernel_size=(1,), stride=(1,))\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer_1): Linear(in_features=4, out_features=50, bias=True)\n",
      "  (layer_2): Linear(in_features=50, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class IrisClassifier(nn.Module):\n",
    "  def __init__(self, num_class, in_ch, out_ch, ker_size=3):\n",
    "    super(IrisClassifier, self).__init__()\n",
    "    self.in_ch = in_ch\n",
    "    self.out_ch = out_ch\n",
    "    self.ker_size = ker_size\n",
    "    \n",
    "    self.conv_1d = nn.Conv1d(in_ch, out_ch, ker_size)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.layer_1 = nn.Linear(out_ch, 50)\n",
    "    self.layer_2 = nn.Linear(50, num_class)\n",
    "        \n",
    "  def forward(self,x):\n",
    "    x = self.conv_1d(x)\n",
    "    x = self.relu(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.layer_1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.layer_2(x)\n",
    "    return x\n",
    "\n",
    "  def train(self, batch):\n",
    "    data, labels = batch \n",
    "    loss = F.cross_entropy(self(data), labels)\n",
    "    acc = accuracy(self(data), labels)\n",
    "    return acc, loss\n",
    "    \n",
    "  def validate(self, batch):\n",
    "    data, labels = batch \n",
    "    loss = F.cross_entropy(self(data), labels)\n",
    "    acc = accuracy(self(data), labels)\n",
    "    return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "  def val_epoch_end(self, outputs):\n",
    "    batch_losses = [x['val_loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()\n",
    "    batch_accs = [x['val_acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()\n",
    "    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "  def model_stat(self, epoch, result):\n",
    "    print(f\"Epoch {epoch}| train [acc: {result['train_acc']:.4f}, loss: {result['train_loss']:.4f}], \\\n",
    "          val [acc: {result['val_acc']:.4f}, val_loss: {result['val_loss']:.4f}]\")\n",
    "\n",
    "# ============================ metrics\n",
    "def accuracy(outputs, labels):\n",
    "  _, preds = torch.max(outputs, dim=1)\n",
    "  acc = torch.sum(preds == labels).item() / len(preds)\n",
    "  return torch.tensor(acc)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "  return model.val_epoch_end(\n",
    "    [model.validate(batch) for batch in val_loader]\n",
    "    )\n",
    "\n",
    "\n",
    "################\n",
    "num_epochs = 30 \n",
    "learning_rate = 0.001\n",
    "\n",
    "in_ch = 4\n",
    "out_ch = 4\n",
    "ker_size = 1\n",
    "num_class = 3\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "train_data = PrepData(X_train, y_train, device)\n",
    "train_dataloader = DataLoader(train_data, batch_size=6)\n",
    "train_dl = DLtoDevice(train_dataloader, device)\n",
    "\n",
    "v_data = PrepData(X_val, y_val, device)\n",
    "v_dataloader = DataLoader(v_data, batch_size=6)\n",
    "val_dl = DLtoDevice(v_dataloader, device)\n",
    "\n",
    "model = to_device(IrisClassifier(num_class, in_ch, out_ch, ker_size), device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0| train [acc: 0.3630, loss: 1.0626],           val [acc: 0.2917, val_loss: 1.0722]\n",
      "Epoch 1| train [acc: 0.3630, loss: 1.0264],           val [acc: 0.2917, val_loss: 1.0597]\n",
      "Epoch 2| train [acc: 0.3630, loss: 0.9876],           val [acc: 0.2917, val_loss: 1.0466]\n",
      "Epoch 3| train [acc: 0.5481, loss: 0.9446],           val [acc: 0.4167, val_loss: 1.0314]\n",
      "Epoch 4| train [acc: 0.7000, loss: 0.8989],           val [acc: 0.5417, val_loss: 1.0127]\n",
      "Epoch 5| train [acc: 0.7574, loss: 0.8535],           val [acc: 0.5417, val_loss: 0.9838]\n",
      "Epoch 6| train [acc: 0.7759, loss: 0.8090],           val [acc: 0.5833, val_loss: 0.9447]\n",
      "Epoch 7| train [acc: 0.7944, loss: 0.7642],           val [acc: 0.5833, val_loss: 0.8994]\n",
      "Epoch 8| train [acc: 0.8037, loss: 0.7191],           val [acc: 0.6250, val_loss: 0.8525]\n",
      "Epoch 9| train [acc: 0.8222, loss: 0.6745],           val [acc: 0.6250, val_loss: 0.8065]\n",
      "Epoch 10| train [acc: 0.8426, loss: 0.6315],           val [acc: 0.6250, val_loss: 0.7612]\n",
      "Epoch 11| train [acc: 0.8611, loss: 0.5897],           val [acc: 0.7083, val_loss: 0.7200]\n",
      "Epoch 12| train [acc: 0.8981, loss: 0.5501],           val [acc: 0.7083, val_loss: 0.6824]\n",
      "Epoch 13| train [acc: 0.9074, loss: 0.5130],           val [acc: 0.7500, val_loss: 0.6497]\n",
      "Epoch 14| train [acc: 0.9074, loss: 0.4785],           val [acc: 0.7500, val_loss: 0.6198]\n",
      "Epoch 15| train [acc: 0.9074, loss: 0.4471],           val [acc: 0.7500, val_loss: 0.5924]\n",
      "Epoch 16| train [acc: 0.9074, loss: 0.4188],           val [acc: 0.7500, val_loss: 0.5678]\n",
      "Epoch 17| train [acc: 0.9074, loss: 0.3933],           val [acc: 0.7500, val_loss: 0.5454]\n",
      "Epoch 18| train [acc: 0.9074, loss: 0.3707],           val [acc: 0.7500, val_loss: 0.5241]\n",
      "Epoch 19| train [acc: 0.9074, loss: 0.3503],           val [acc: 0.7500, val_loss: 0.5055]\n",
      "Epoch 20| train [acc: 0.9167, loss: 0.3325],           val [acc: 0.7500, val_loss: 0.4870]\n",
      "Epoch 21| train [acc: 0.9167, loss: 0.3163],           val [acc: 0.7500, val_loss: 0.4699]\n",
      "Epoch 22| train [acc: 0.9167, loss: 0.3017],           val [acc: 0.7500, val_loss: 0.4522]\n",
      "Epoch 23| train [acc: 0.9167, loss: 0.2882],           val [acc: 0.7500, val_loss: 0.4345]\n",
      "Epoch 24| train [acc: 0.9259, loss: 0.2752],           val [acc: 0.7500, val_loss: 0.4187]\n",
      "Epoch 25| train [acc: 0.9259, loss: 0.2635],           val [acc: 0.7083, val_loss: 0.4021]\n",
      "Epoch 26| train [acc: 0.9352, loss: 0.2524],           val [acc: 0.7083, val_loss: 0.3862]\n",
      "Epoch 27| train [acc: 0.9352, loss: 0.2420],           val [acc: 0.7083, val_loss: 0.3702]\n",
      "Epoch 28| train [acc: 0.9444, loss: 0.2322],           val [acc: 0.7083, val_loss: 0.3544]\n",
      "Epoch 29| train [acc: 0.9444, loss: 0.2227],           val [acc: 0.7083, val_loss: 0.3393]\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "for epoch in range(num_epochs):\n",
    "  train_acc = []\n",
    "  train_losses = []\n",
    "  for batch in train_dl:\n",
    "    acc, loss = model.train(batch)\n",
    "    train_acc.append(acc)\n",
    "    train_losses.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # validate\n",
    "    result = evaluate(model, val_dl)\n",
    "    result['train_acc'] = torch.stack(train_acc).mean().item()\n",
    "    result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "    \n",
    "  model.model_stat(epoch, result)\n",
    "  if result['val_acc'] > best_acc:\n",
    "    best_acc = result['val_acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9130434782608695\n",
      "23 [2 1 1 2 1 2 1 1 0 1 0 2 1 2 0 2 0 1 0 0 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "_test = Variable(torch.from_numpy(X_test)).float()\n",
    "pred = model(to_device(_test, device))\n",
    "pred = pred.cpu().detach().numpy()\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y_test, np.argmax(pred, axis=1)))\n",
    "print(len(pred), np.argmax(pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
